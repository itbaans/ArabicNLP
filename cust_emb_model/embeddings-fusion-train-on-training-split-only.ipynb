{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12701773,"sourceType":"datasetVersion","datasetId":8027417}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:06.235295Z","iopub.execute_input":"2025-08-14T11:29:06.235460Z","iopub.status.idle":"2025-08-14T11:29:06.550561Z","shell.execute_reply.started":"2025-08-14T11:29:06.235445Z","shell.execute_reply":"2025-08-14T11:29:06.549708Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nfrom PIL import Image\nfrom transformers import (\n    CLIPProcessor, CLIPModel, CLIPVisionModel,\n    AutoModel, AutoProcessor, AutoTokenizer,\n    AutoModelForMaskedLM\n)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport numpy as np\nfrom collections import Counter, defaultdict\nimport os\nimport json\nfrom datetime import datetime\nimport pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:06.552751Z","iopub.execute_input":"2025-08-14T11:29:06.553059Z","iopub.status.idle":"2025-08-14T11:29:32.702335Z","shell.execute_reply.started":"2025-08-14T11:29:06.553043Z","shell.execute_reply":"2025-08-14T11:29:32.701614Z"}},"outputs":[{"name":"stderr","text":"2025-08-14 11:29:14.338731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755170954.644789     111 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755170954.727996     111 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import random\nimport torch\nimport numpy as np\n\n# Set seeds for reproducibility\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(461)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.703197Z","iopub.execute_input":"2025-08-14T11:29:32.703854Z","iopub.status.idle":"2025-08-14T11:29:32.716018Z","shell.execute_reply.started":"2025-08-14T11:29:32.703833Z","shell.execute_reply":"2025-08-14T11:29:32.715196Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def worker_init_fn(worker_id):\n    np.random.seed(461 + worker_id)\n\ng = torch.Generator()\ng.manual_seed(461)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.716923Z","iopub.execute_input":"2025-08-14T11:29:32.717140Z","iopub.status.idle":"2025-08-14T11:29:32.733637Z","shell.execute_reply.started":"2025-08-14T11:29:32.717117Z","shell.execute_reply":"2025-08-14T11:29:32.732748Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7dc543e2e570>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"class PrecomputedEmbeddingsDataset(Dataset):\n    def __init__(self, jsonl_path, embeddings_path, is_test=False):\n        \"\"\"\n        Args:\n            jsonl_path (str): Path to the original .jsonl file\n            embeddings_path (str): Path to JSON file with precomputed embeddings\n            is_test (bool): If True, skips loading labels (for test data)\n        \"\"\"\n        self.data = load_dataset('json', data_files=jsonl_path)['train']\n        with open(embeddings_path, 'r') as f:\n            self.embeddings = json.load(f)\n        \n        self.is_test = is_test\n        if not self.is_test:\n            self.labels = self.data['label']\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        item = self.data[idx]\n        id_val = str(item['id'])  # JSON keys are strings\n        \n        if id_val not in self.embeddings:\n            raise KeyError(f\"Embeddings for ID {id_val} not found\")\n        \n        emb_data = self.embeddings[id_val]\n        \n        output = {\n            'image_embedding': torch.tensor(emb_data['image_embedding']),\n            'text_embedding': torch.tensor(emb_data['text_embedding']),\n        }\n        \n        if not self.is_test:\n            output['label'] = torch.tensor(item['label'], dtype=torch.long)\n        if self.is_test:\n            output['id'] = item['id']\n        \n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.734527Z","iopub.execute_input":"2025-08-14T11:29:32.734896Z","iopub.status.idle":"2025-08-14T11:29:32.754381Z","shell.execute_reply.started":"2025-08-14T11:29:32.734878Z","shell.execute_reply":"2025-08-14T11:29:32.753523Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class PrecomputedEmbeddingsClassifier(nn.Module):\n    def __init__(self, \n                 image_embedding_dim, \n                 text_embedding_dim,\n                 fusion_type='gate',\n                 projection_dim=256, \n                 dropout_rate=0.2,\n                 num_classes=2):\n        super().__init__()\n        self.fusion_type = fusion_type\n        \n        # Fusion configuration\n        if fusion_type == 'concat':\n            classifier_input_dim = image_embedding_dim + text_embedding_dim\n        else:\n            classifier_input_dim = projection_dim\n        \n        # Projection layers for non-concat methods\n        if fusion_type in ['add', 'mul', 'gate']:\n            self.image_proj = nn.Linear(image_embedding_dim, projection_dim)\n            self.text_proj = nn.Linear(text_embedding_dim, projection_dim)\n            self.norm = nn.LayerNorm(projection_dim)\n        \n        # Gated fusion components\n        if fusion_type == 'gate':\n            self.image_gate = nn.Linear(image_embedding_dim, projection_dim)\n            self.text_gate = nn.Linear(text_embedding_dim, projection_dim)\n            self.sigmoid = nn.Sigmoid()\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(classifier_input_dim, projection_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout_rate),\n            nn.Linear(projection_dim, num_classes)\n        )\n\n    def forward(self, image_embedding, text_embedding):\n        # Apply fusion technique\n        if self.fusion_type == 'concat':\n            combined = torch.cat((image_embedding, text_embedding), dim=-1)\n        \n        elif self.fusion_type == 'add':\n            img_proj = F.relu(self.image_proj(image_embedding))\n            txt_proj = F.relu(self.text_proj(text_embedding))\n            combined = img_proj + txt_proj\n            combined = self.norm(combined)\n        \n        elif self.fusion_type == 'mul':\n            img_proj = F.relu(self.image_proj(image_embedding))\n            txt_proj = F.relu(self.text_proj(text_embedding))\n            combined = img_proj * txt_proj\n            combined = self.norm(combined)\n        \n        elif self.fusion_type == 'gate':\n            img_proj = F.relu(self.image_proj(image_embedding))\n            txt_proj = F.relu(self.text_proj(text_embedding))\n            \n            # Compute gating weights\n            gate_img = self.sigmoid(self.image_gate(image_embedding))\n            gate_txt = self.sigmoid(self.text_gate(text_embedding))\n            \n            # Apply gating mechanism\n            combined = gate_img * img_proj + gate_txt * txt_proj\n            combined = self.norm(combined)\n        \n        # Final classification\n        logits = self.classifier(combined)\n        return logits\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.755260Z","iopub.execute_input":"2025-08-14T11:29:32.755551Z","iopub.status.idle":"2025-08-14T11:29:32.777094Z","shell.execute_reply.started":"2025-08-14T11:29:32.755527Z","shell.execute_reply":"2025-08-14T11:29:32.776440Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import json\nfrom sklearn.metrics import classification_report\n\ndef train_model(\n    model,\n    train_loader,\n    dev_loader,\n    criterion,\n    device,\n    learning_rate=5e-5,\n    num_epochs=100,\n    early_stop_patience=100,\n    weight_decay=1e-5,\n    clip_value=1.0,\n    model_save_path='best_model.pth',\n    metrics_file_path='training_metrics.json',\n    shedular_step=True\n):\n    # Initialize metrics dictionary\n    metrics = {\n        'epochs': [],\n        'train_losses': [],\n        'val_f1_macro': [],\n        'best_f1': 0,\n        'best_epoch': 0,\n        'classification_reports': {}\n    }\n    \n    model = model.to(device)\n    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n    \n    best_f1 = 0\n    epochs_no_improve = 0\n\n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        total_loss = 0\n        \n        for i, batch in enumerate(train_loader):\n            img_emb = batch['image_embedding'].to(device, non_blocking=True)\n            txt_emb = batch['text_embedding'].to(device, non_blocking=True)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            logits = model(img_emb, txt_emb)\n            loss = criterion(logits, labels)\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n            optimizer.step()\n\n            total_loss += loss.item()\n            if (i + 1) % 50 == 0:\n                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n\n        # Validation\n        model.eval()\n        all_preds, all_labels = [], []\n        \n        with torch.no_grad():\n            for batch in dev_loader:\n                img_emb = batch['image_embedding'].to(device, non_blocking=True)\n                txt_emb = batch['text_embedding'].to(device, non_blocking=True)\n                labels = batch['label'].to(device)\n                \n                logits = model(img_emb, txt_emb)\n                preds = torch.argmax(logits, dim=1)\n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n        \n        # Calculate metrics\n        f1 = f1_score(all_labels, all_preds, average='macro')\n        avg_train_loss = total_loss / len(train_loader)\n        \n        # Record metrics\n        metrics['epochs'].append(epoch + 1)\n        metrics['train_losses'].append(avg_train_loss)\n        metrics['val_f1_macro'].append(f1)\n        \n        print(f\"\\nEpoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val F1: {f1:.4f}\")\n        \n        if shedular_step:\n            scheduler.step(f1)\n        \n        # Check for new best score\n        if f1 > best_f1:\n            best_f1 = f1\n            metrics['best_f1'] = best_f1\n            metrics['best_epoch'] = epoch + 1\n            epochs_no_improve = 0\n            \n            # Save model\n            torch.save(model.state_dict(), model_save_path)\n            \n            # Generate and save classification report\n            report = classification_report(\n                all_labels, \n                all_preds,\n                output_dict=True\n            )\n            metrics['classification_reports'][f'epoch_{epoch+1}'] = report\n            \n            # Save metrics to file\n            with open(metrics_file_path, 'w') as f:\n                json.dump(metrics, f, indent=4)\n                \n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve == early_stop_patience:\n                print(f\"Early stopping triggered at epoch {epoch+1}\")\n                # Save metrics before early stopping\n                with open(metrics_file_path, 'w') as f:\n                    json.dump(metrics, f, indent=4)\n                break\n        \n        # Save metrics after each epoch (in case of interruption)\n        with open(metrics_file_path, 'w') as f:\n            json.dump(metrics, f, indent=4)\n\n    print(\"Training complete. Loading best model.\")\n    model.load_state_dict(torch.load(model_save_path))\n    \n    return model, best_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.778130Z","iopub.execute_input":"2025-08-14T11:29:32.778451Z","iopub.status.idle":"2025-08-14T11:29:32.800864Z","shell.execute_reply.started":"2025-08-14T11:29:32.778423Z","shell.execute_reply":"2025-08-14T11:29:32.800097Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\ndef generate_predictions(model, test_loader, output_path=\"prediction.csv\", device='cuda'):\n    \"\"\"\n    Generate predictions using a trained model and save them to a CSV file.\n    \n    Args:\n        model: Trained PyTorch model\n        test_loader: DataLoader for test data\n        output_path (str): Path to save predictions CSV (default: \"prediction.csv\")\n        device (str): Device to use for inference ('cuda' or 'cpu')\n    \"\"\"\n    model.eval()\n    predictions = []\n    ids = []\n\n    with torch.no_grad():\n        for batch in test_loader:\n            # Move batch data to device\n            img_emb = batch['image_embedding'].to(device, non_blocking=True)\n            txt_emb = batch['text_embedding'].to(device, non_blocking=True)\n                    \n            # Get model predictions\n            logits = model(img_emb, txt_emb)\n            preds = torch.argmax(logits, dim=1)\n\n            # Store predictions and IDs\n            predictions.extend(preds.cpu().numpy())\n            \n            # Handle IDs (convert to list if tensor)\n            batch_ids = batch['id']\n            if isinstance(batch_ids, torch.Tensor):\n                batch_ids = batch_ids.tolist()\n            ids.extend(batch_ids)\n\n    # Convert numerical predictions to labels\n    label_map = {0: 'not-hate', 1: 'hate'}\n    pred_labels = [label_map[p] for p in predictions]\n\n    # Save to CSV\n    df = pd.DataFrame({\n        'id': ids,\n        'prediction': pred_labels\n    })\n    df.to_csv(output_path, index=False)\n    print(f\"Predictions saved to {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.802983Z","iopub.execute_input":"2025-08-14T11:29:32.803302Z","iopub.status.idle":"2025-08-14T11:29:32.822784Z","shell.execute_reply.started":"2025-08-14T11:29:32.803283Z","shell.execute_reply":"2025-08-14T11:29:32.822279Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import (classification_report, roc_auc_score, \n                             f1_score, precision_score, recall_score, \n                             accuracy_score, confusion_matrix)\nimport json\n\ndef evaluate_classification_performance(true_labels_path, predictions_path, output_file_path='classification_metrics.json'):\n    \"\"\"\n    Evaluate classification performance by comparing true labels with predictions and save results to a file.\n    \n    Args:\n        true_labels_path (str): Path to CSV file containing true labels (columns: id, test_label)\n        predictions_path (str): Path to CSV file containing predictions (columns: id, prediction)\n        output_file_path (str): Path to save the evaluation metrics (default: 'classification_metrics.json')\n    \"\"\"\n    # Load the data\n    test_df = pd.read_csv(true_labels_path)\n    pred_df = pd.read_csv(predictions_path)\n\n    # Initialize results dictionary\n    results = {\n        'classification_report': {},\n        'additional_metrics': {},\n        'confusion_matrix': []\n    }\n\n    # Verify the IDs match (just in case)\n    if not (test_df['id'] == pred_df['id']).all():\n        print(\"Warning: IDs don't match between files! Results may be invalid.\")\n        # Alternative approach if IDs don't match:\n        merged = pd.merge(test_df, pred_df, on='id', how='inner')\n        y_true = merged['testing_label']\n        y_pred = merged['prediction']\n    else:\n        y_true = test_df['testing_label']\n        y_pred = pred_df['prediction']\n\n    # For binary classification, convert to numerical if needed\n    label_map = {'hate': 1, 'not-hate': 0}\n    if y_true.dtype == 'object':\n        y_true_num = y_true.map(label_map)\n        y_pred_num = y_pred.map(label_map)\n    else:\n        y_true_num = y_true\n        y_pred_num = y_pred\n\n    # Calculate and store classification report\n    clf_report = classification_report(y_true, y_pred, target_names=['not-hate', 'hate'], output_dict=True)\n    results['classification_report'] = clf_report\n    \n    # Calculate and store additional metrics\n    results['additional_metrics'] = {\n        'accuracy': accuracy_score(y_true_num, y_pred_num),\n        'f1_macro': f1_score(y_true_num, y_pred_num, average='macro'),\n        'precision_macro': precision_score(y_true_num, y_pred_num, average='macro'),\n        'recall_macro': recall_score(y_true_num, y_pred_num, average='macro')\n    }\n\n    # Calculate and store confusion matrix\n    results['confusion_matrix'] = confusion_matrix(y_true_num, y_pred_num).tolist()\n\n    # Print results to console\n    print(\"Classification Report:\")\n    print(classification_report(y_true, y_pred, target_names=['not-hate', 'hate']))\n\n    print(\"\\nAdditional Metrics:\")\n    print(f\"Accuracy: {results['additional_metrics']['accuracy']:.4f}\")\n    print(f\"F1 Macro: {results['additional_metrics']['f1_macro']:.4f}\")\n    print(f\"Precision Macro: {results['additional_metrics']['precision_macro']:.4f}\")\n    print(f\"Recall Macro: {results['additional_metrics']['recall_macro']:.4f}\")\n\n    print(\"\\nConfusion Matrix:\")\n    print(results['confusion_matrix'])\n\n    # Save results to file\n    with open(output_file_path, 'w') as f:\n        json.dump(results, f, indent=4)\n    \n    print(f\"\\nAll metrics saved to {output_file_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.823741Z","iopub.execute_input":"2025-08-14T11:29:32.823996Z","iopub.status.idle":"2025-08-14T11:29:32.844532Z","shell.execute_reply.started":"2025-08-14T11:29:32.823974Z","shell.execute_reply":"2025-08-14T11:29:32.843995Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"DEVICE='cuda'\n\ntrain_dataset = PrecomputedEmbeddingsDataset(\n    jsonl_path=\"/kaggle/input/qcri-final-folder/QCRI_ARABIC_FOLDER/new_train.jsonl\",\n    embeddings_path=\"/kaggle/input/qcri-final-folder/QCRI_ARABIC_FOLDER/embeddings.json\"\n)\n\nval_dataset = PrecomputedEmbeddingsDataset(\n    jsonl_path=\"/kaggle/input/qcri-final-folder/QCRI_ARABIC_FOLDER/new_test.jsonl\",\n    embeddings_path=\"/kaggle/input/qcri-final-folder/QCRI_ARABIC_FOLDER/embeddings.json\"\n)\n\nlabel_counts = Counter(train_dataset.labels)\n\nsample = train_dataset[0]\n\n\n# Create data loaders\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=32, \n    shuffle=True,\n    generator=g,\n    worker_init_fn=worker_init_fn\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=32, \n    shuffle=False,\n    worker_init_fn=worker_init_fn\n)\n\n\nUSE_FOCAL_LOSS=True\n\n# Focal Loss for class imbalance (handles hard examples)\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        loss = (1 - pt) ** self.gamma * ce_loss\n        if self.alpha is not None:\n            loss = self.alpha[targets] * loss\n        return loss.mean()\n\n# Class-aware loss weighting\nloss_weights = torch.tensor([\n    len(train_dataset) / (2 * label_counts[0]),\n    len(train_dataset) / (2 * label_counts[1])\n], dtype=torch.float32).to(DEVICE)\n\ncriterion = FocalLoss(alpha=loss_weights) if USE_FOCAL_LOSS \\\n            else nn.CrossEntropyLoss(weight=loss_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:29:32.845171Z","iopub.execute_input":"2025-08-14T11:29:32.845360Z","iopub.status.idle":"2025-08-14T11:29:39.019420Z","shell.execute_reply.started":"2025-08-14T11:29:32.845346Z","shell.execute_reply":"2025-08-14T11:29:39.018555Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda398218bc34ca7a01f3be51264fc46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28215536773418e9cb04c77165bb257"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model = PrecomputedEmbeddingsClassifier(\n    image_embedding_dim=sample['image_embedding'].shape[0],\n    text_embedding_dim=sample['text_embedding'].shape[0],\n    fusion_type='gate', \n    projection_dim=256,\n    num_classes=2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:31:42.257333Z","iopub.execute_input":"2025-08-14T11:31:42.258214Z","iopub.status.idle":"2025-08-14T11:31:42.269410Z","shell.execute_reply.started":"2025-08-14T11:31:42.258183Z","shell.execute_reply":"2025-08-14T11:31:42.268751Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Train model\ntrained_model, best_f1 = train_model(\n    model=model,\n    train_loader=train_loader,\n    dev_loader=val_loader,\n    criterion=criterion,\n    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    num_epochs=30,\n    learning_rate=5e-5,\n    early_stop_patience=10,\n    model_save_path='best_model_custom_emb_fusion.pth',\n    metrics_file_path='training_metrics_custom_emb_fusion.json'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:28:53.986012Z","iopub.status.idle":"2025-08-14T11:28:53.986242Z","shell.execute_reply.started":"2025-08-14T11:28:53.986144Z","shell.execute_reply":"2025-08-14T11:28:53.986153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = PrecomputedEmbeddingsDataset(\n    jsonl_path=\"/kaggle/input/qcri-final-folder/QCRI_ARABIC_FOLDER/task3_test_without_label.jsonl\",\n    embeddings_path=\"/kaggle/input/qcri-final-folder/QCRI_ARABIC_FOLDER/embeddings.json\",\n    is_test=True\n)\n\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T12:11:22.283416Z","iopub.execute_input":"2025-08-14T12:11:22.283762Z","iopub.status.idle":"2025-08-14T12:11:24.244336Z","shell.execute_reply.started":"2025-08-14T12:11:22.283740Z","shell.execute_reply":"2025-08-14T12:11:24.243709Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"generate_predictions(trained_model, test_loader, \"official_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T09:41:53.921505Z","iopub.execute_input":"2025-08-14T09:41:53.921773Z","iopub.status.idle":"2025-08-14T09:41:54.059125Z","shell.execute_reply.started":"2025-08-14T09:41:53.921754Z","shell.execute_reply":"2025-08-14T09:41:54.058247Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to official_predictions.csv\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# Example usage:\nevaluate_classification_performance(\n    '/kaggle/input/qcri-final-folder/QCRI_ARABIC_FOLDER/task3_test_gold.txt',\n    '/kaggle/working/official_predictions.csv',\n    output_file_path='classification_metrics.json_custom_emb_fusion'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T09:49:33.297831Z","iopub.execute_input":"2025-08-14T09:49:33.298425Z","iopub.status.idle":"2025-08-14T09:49:33.358285Z","shell.execute_reply.started":"2025-08-14T09:49:33.298400Z","shell.execute_reply":"2025-08-14T09:49:33.357677Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n    not-hate       0.76      0.54      0.63       200\n        hate       0.74      0.89      0.81       300\n\n    accuracy                           0.75       500\n   macro avg       0.75      0.71      0.72       500\nweighted avg       0.75      0.75      0.74       500\n\n\nAdditional Metrics:\nAccuracy: 0.7480\nF1 Macro: 0.7200\nPrecision Macro: 0.7518\nRecall Macro: 0.7133\n\nConfusion Matrix:\n[[266, 34], [92, 108]]\n\nAll metrics saved to classification_metrics.json_custom_emb_fusion\n","output_type":"stream"}],"execution_count":54}]}